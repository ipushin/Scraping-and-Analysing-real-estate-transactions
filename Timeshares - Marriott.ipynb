{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "from calendar import monthrange\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_batch(soup):\n",
    "    \n",
    "    party_code = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'party_code'})):\n",
    "        party_code.append(el.text)\n",
    "    \n",
    "    party_name = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'party_name'})):\n",
    "        if el.text != 'Name':\n",
    "            party_name.append(el.text)\n",
    "    \n",
    "    cross_party_name = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'cross_party_name'})):\n",
    "        if el.text != 'Cross Party':\n",
    "            cross_party_name.append(el.text)\n",
    "    \n",
    "    rec_date = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'rec_date'})):\n",
    "        if el.text != 'Date':\n",
    "            rec_date.append(el.text)\n",
    "    doc_type = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'doc_type'})):\n",
    "        if el.text != 'Type':\n",
    "            doc_type.append(el.text)\n",
    "    \n",
    "    book = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'book'})):\n",
    "        if el.text != 'Book':\n",
    "            book.append(el.text)\n",
    "    \n",
    "    page = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'page'})):\n",
    "        if el.text != 'Page':\n",
    "            page.append(el.text)\n",
    "    \n",
    "    legal_1 = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'legal_1'})):\n",
    "        if el.text != 'Legal':\n",
    "            legal_1.append(el.text)\n",
    "    \n",
    "    file_num = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'file_num'})):\n",
    "        if el.text != 'Instr#':\n",
    "            file_num.append(el.text)\n",
    "    \n",
    "    doc_status = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'doc_status'})):\n",
    "        if el.text != 'Status':\n",
    "            doc_status.append(el.text)\n",
    "    \n",
    "    batch = pd.DataFrame({'Party Code':party_code[1:],\n",
    "                          'Party Name':party_name,\n",
    "                          'Cross Party Name':cross_party_name,\n",
    "                          'Date':rec_date,\n",
    "                          'Doc Type':doc_type,\n",
    "                          'Book':book,\n",
    "                          'Page':page,\n",
    "                          'Legal':legal_1,\n",
    "                          'Instr#':file_num,\n",
    "                          'Doc Status':doc_status})\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_and_scrape(returned_rows):\n",
    "    table = pd.DataFrame([])\n",
    "    for i in range(0,50):\n",
    "        try:\n",
    "            browser.implicitly_wait(1)\n",
    "            if i == 0:\n",
    "                browser.implicitly_wait(3)\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                browser.implicitly_wait(1)\n",
    "                try:\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[10]/div[3]'\n",
    "                    element = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    print('except 10th element')\n",
    "                    browser.implicitly_wait(1)\n",
    "                    row = randint(3,10)\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[{}]/div[3]'.format(row)\n",
    "                    element = WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(3):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.2)\n",
    "            else:\n",
    "                browser.implicitly_wait(0.5)\n",
    "                try:\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[30]/div[3]'\n",
    "                    element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    browser.implicitly_wait(1)\n",
    "                    row = randint(10,20)\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[{}]/div[3]'.format(row)\n",
    "                    element = WebDriverWait(browser, 5).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click().click()\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(2):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.2)\n",
    "\n",
    "            if i%2==0:\n",
    "                browser.implicitly_wait(1)\n",
    "                sleep(0.1) \n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                dupl = table[table.duplicated(subset=table.columns, keep='first')]\n",
    "\n",
    "            clean_table = table.drop_duplicates(subset=table.columns, keep='first').copy()\n",
    "            if clean_table.shape[0] >= 0.99*returned_rows:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[2]/p/input'\n",
    "end_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[3]/p/input'\n",
    "search_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[3]/button[2]'\n",
    "back_search_path = '/html/body/div[1]/div[3]/ul/li[1]/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selenium\n",
    "browser = webdriver.Chrome('/Users/macbook/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://rodweb.bcgov.net/BrowserViewDMP/'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[2]/div/input'\n",
    "browser.find_element_by_xpath(owner_path).send_keys('MARRIOTT OWNERSHIP RESORTS INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document type\n",
    "type_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[2]/div[2]/input'\n",
    "browser.find_element_by_xpath(type_path).send_keys('DEED,RED,REDC,REDH,REDM,TSD,TSDHH,TSDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5a5bddae07a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmarriott_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Marriott.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmarriott_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "marriott_table=pd.read_csv('Marriott.csv', index_col=[0])\n",
    "marriott_table.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriott_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for year in range(2009,2021):\n",
    "    year = str(year)\n",
    "    for month_num in range(1,13):\n",
    "        month_table = pd.DataFrame([])\n",
    "        date_start = '01'\n",
    "        end_of_month = str(monthrange(int(year), month_num)[1])\n",
    "        comul_rows = 0\n",
    "        for i in range(30): \n",
    "            #print('\\n')\n",
    "            print('Batch #'+str(i))\n",
    "           \n",
    "            if i == 0:\n",
    "                date_end = str(monthrange(int(year), month_num)[1])\n",
    "            \n",
    "            if len(str(month_num)) < 2:\n",
    "                month = '0' + str(month_num)\n",
    "            else:\n",
    "                month = str(month_num)\n",
    "            returned_rows=1001\n",
    "            \n",
    "            # update end and start date       \n",
    "            browser.find_element_by_xpath(start_date_path).send_keys('{}/{}/{}'.format(month, date_start, year)) \n",
    "            browser.find_element_by_xpath(end_date_path).send_keys('{}/{}/{}'.format(month, date_end, year))\n",
    "\n",
    "            # click search\n",
    "            sleep(0.3)\n",
    "            browser.find_element_by_xpath(search_path).click()\n",
    "\n",
    "            try:\n",
    "                sleep(0.5)\n",
    "                ret_rows_path = '//*[@id=\"results\"]/div[6]/div/div[2]'\n",
    "                element = WebDriverWait(browser, randint(1,4)).until(EC.element_to_be_clickable((By.XPATH, ret_rows_path)))\n",
    "                returned_rows = element.text\n",
    "                returned_rows = int(re.findall(r'(\\d+(?= total))', returned_rows)[0])\n",
    "                comul_rows += returned_rows\n",
    "                #print('Comul Rows:', comul_rows)\n",
    "                print('Month', month, 'Date Start:', date_start, 'Date End:', date_end, 'Returned Rows:', returned_rows)\n",
    "\n",
    "                if date_start == '01' and date_end == end_of_month:\n",
    "                    rows_month_total = returned_rows\n",
    "                \n",
    "            except:\n",
    "                try:\n",
    "                    sleep(randint(2,3))\n",
    "                    #browser.implicitly_wait(3)\n",
    "                    popup = browser.switch_to.alert\n",
    "                    returned_rows = int(re.findall(r'(\\d+(?= results))', popup.text)[0])\n",
    "                    print('Month', month, 'Date Start:', date_start, 'Date End:', date_end, 'Returned Rows:', returned_rows)\n",
    "                    if date_start == '01' and date_end == end_of_month: \n",
    "                        rows_month_total = returned_rows\n",
    "                    \n",
    "                except:\n",
    "                    not_found = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "\n",
    "                    if not_found:\n",
    "                        print('No records')\n",
    "                        # back to search\n",
    "                        sleep(0.3)\n",
    "                        browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                        # clear end and start date\n",
    "                        browser.implicitly_wait(0.3)\n",
    "                        browser.find_element_by_xpath(end_date_path).clear()\n",
    "                        browser.find_element_by_xpath(start_date_path).clear()\n",
    "                        break\n",
    "\n",
    "            while returned_rows > 1000:\n",
    "                try:\n",
    "                    try:\n",
    "                        browser.implicitly_wait(3)\n",
    "                        alert = browser.switch_to_alert()\n",
    "                        alert.accept()\n",
    "                    except:\n",
    "                        continue\n",
    "                    try:\n",
    "                        # back to search\n",
    "                        element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, back_search_path)))\n",
    "                        element.click()\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    # clear end date\n",
    "                    browser.implicitly_wait(1)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "\n",
    "                    # end date chuncking, update end date\n",
    "                    sleep(1)\n",
    "                    if len(date_start)>1 and date_start[0]==0:\n",
    "                        date_start_num = int(date_start[1])\n",
    "                    else:\n",
    "                        date_start_num = int((date_start))\n",
    "\n",
    "                    if len(date_end)>1 and date_end[0]==0:\n",
    "                        date_end_num = int(date_end[1])\n",
    "                    else:\n",
    "                        date_end_num = int((date_end))\n",
    "\n",
    "                    date_end = math.trunc(date_start_num + (date_end_num-date_start_num)/(returned_rows/1000))\n",
    "                    date_end = str(date_end)\n",
    "\n",
    "                    \n",
    "                    if len(date_end) < 2:\n",
    "                        date_end = '0' + date_end\n",
    "\n",
    "                    browser.find_element_by_xpath(end_date_path).send_keys('{}/{}/{}'.format(month,date_end,year))\n",
    "\n",
    "                    # click search\n",
    "                    browser.find_element_by_xpath(search_path).click()\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # check updated results\n",
    "                try:\n",
    "                    sleep(randint(2,3))\n",
    "                    popup = browser.switch_to.alert\n",
    "                    returned_rows = int(re.findall(r'(\\d+(?= results))', popup.text)[0])\n",
    "                    print('Date Start:', date_start, ' Updated Date End:', date_end, 'Returned rows:', returned_rows)\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        returned_rows = browser.find_element_by_xpath('//*[@id=\"results\"]/div[6]/div/div[2]').text\n",
    "                        returned_rows = int(re.findall(r'(\\d+(?= total))', returned_rows)[0])\n",
    "                        comul_rows += returned_rows\n",
    "                        print('Comul Rows:', comul_rows)\n",
    "                        print('Date Start:', date_start, ' Updated Date End:', date_end, 'Returned rows:', returned_rows)\n",
    "                        \n",
    "                    except:\n",
    "                        returned_rows = 999\n",
    "                        not_found = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "                        if not_found:\n",
    "                            returned_rows = 999\n",
    "                            pass\n",
    "\n",
    "            # if <1000 on the first step\n",
    "            else:\n",
    "                if returned_rows < 60:\n",
    "                    sleep(0.5)\n",
    "                    html = browser.page_source\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    batch = get_table_batch(soup)\n",
    "                    month_table = pd.concat([month_table, batch], axis=0)\n",
    "\n",
    "                    # back to search\n",
    "                    browser.implicitly_wait(1.5)\n",
    "                    browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                    # clear end and start date\n",
    "                    browser.implicitly_wait(0.3)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "                    browser.find_element_by_xpath(start_date_path).clear()\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "        \n",
    "                    batch = scroll_and_scrape(returned_rows)\n",
    "                    print('Batch Rows:', batch.shape[0], 'Percent of records: {}%'.format(round(batch.shape[0]/returned_rows*100, 1)))\n",
    "                    sleep(0.5) \n",
    "                    month_table = pd.concat([month_table, batch], axis=0)\n",
    "                    month_table['Start Date'] = date_start\n",
    "                    month_table['End Date'] = date_end\n",
    "                    month_table['Percentage of data'] = round(batch.shape[0]/returned_rows*100, 1)\n",
    "\n",
    "                    date_start = str(int(date_end)+1)\n",
    "\n",
    "                    #EDIT\n",
    "                    if date_end==end_of_month: \n",
    "                    #print('Final Step', 'Rows Month Total:', rows_month_total)\n",
    "                        print('Month table rows:', month_table.shape[0], 'Percent of total: {}%'.format(round(month_table.shape[0]/rows_month_total*100, 1))) \n",
    "                        # back to search\n",
    "                        sleep(0.3)\n",
    "                        browser.implicitly_wait(1)\n",
    "                        browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                        # clear end and start date\n",
    "                        browser.implicitly_wait(0.3)\n",
    "                        browser.find_element_by_xpath(end_date_path).clear()\n",
    "                        browser.find_element_by_xpath(start_date_path).clear()\n",
    "\n",
    "                        break\n",
    "\n",
    "                    date_end = math.trunc(int(date_start) + (int(end_of_month)-int(date_start))/((rows_month_total-comul_rows*0.99)/1000))\n",
    "                    if date_end > int(end_of_month):\n",
    "                        date_end = end_of_month\n",
    "                    date_end = str(date_end)\n",
    "                    if len(date_end) < 2:\n",
    "                            date_end = '0' + date_end\n",
    "\n",
    "                    if len(date_start) < 2:\n",
    "                        date_start = '0' + date_start\n",
    "\n",
    "\n",
    "                    if len(date_start) < 2:\n",
    "                        date_start = '0' + date_start\n",
    "\n",
    "                    # back to search\n",
    "                    sleep(0.3)\n",
    "                    browser.implicitly_wait(1)\n",
    "                    browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                    # clear end and start date\n",
    "                    browser.implicitly_wait(0.3)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "                    browser.find_element_by_xpath(start_date_path).clear()\n",
    "\n",
    "        \n",
    "        #marriott_table = pd.concat([marriott_table, month_table], axis=0)\n",
    "        #marriott_table.to_csv('----.csv')\n",
    "        print('Marriott Table Rows:', marriott_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_table_final.to_csv('timeshares_{}'.format('2012'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one = pd.read_csv('timeshares_{}'.format('2012_1-8'))\n",
    "#two = pd.read_csv('timeshares_{}'.format('2011_3_to_04'))\n",
    "#three = pd.read_csv('timeshares_{}'.format('2011'))\n",
    "#year_table_final = pd.concat([one, year_table], axis=0)\n",
    "#year_table_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_table.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table.drop_duplicates(subset=year_table.columns[:8], keep='first').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "scope = ['https://spreadsheets.google.com/feeds'] \n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('jupyter-sheets-270906-86a657daa9f6.json', scope) \n",
    "gc = gspread.authorize(credentials)\n",
    "spreadsheet_key = '1nZdhq0xaSkdExyHbkgPwF56N8RBzRnimgHQsFILQ7co'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2g.upload(table.reset_index(drop=True),\n",
    "           spreadsheet_key,\n",
    "           'Sample',\n",
    "           credentials=credentials,\n",
    "           col_names=True,\n",
    "           row_names=False,\n",
    "           start_cell = 'A1',\n",
    "           clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def scroll_down_element(element):\n",
    "    try:\n",
    "        browser.execute_script(\"arguments[0].scrollTop = 200\", element)\n",
    "\n",
    "    except Exception as e:\n",
    "        print ('error scrolling down web element', e)\n",
    "element = browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[33]/div[4]')\n",
    "scroll_down_element(element)\n",
    "#element = browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[33]/div[4]')\n",
    "#for _ in range(10):\n",
    "   # browser.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "    #sleep(1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "                print('EXCEPT rows', returned_rows)\n",
    "                date_start = str(date_end)\n",
    "                print('NOT FOUND day start', date_start)\n",
    "                if len(date_start) < 2:\n",
    "                    date_start = '0' + date_start\n",
    "                sleep(2)\n",
    "                # back to search\n",
    "                browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                # clear end and start date\n",
    "                browser.implicitly_wait(1)\n",
    "                browser.find_element_by_xpath(end_date_path).clear()\n",
    "                browser.find_element_by_xpath(start_date_path).clear()\n",
    "                '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #date_end = math.trunc(date_start_num + (date_end_num-date_start_num)/(count*2+1))\n",
    "        \n",
    "    ''' \n",
    "    except:\n",
    "        print('Test')\n",
    "        try:\n",
    "            records_found = browser.find_element_by_xpath('//*[@id=\"results\"]/div[6]/div/div[2]').text\n",
    "            print(records_found)\n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    "                    print('Less than thousand rows (before loop):', returned_rows)\n",
    "                    browser.implicitly_wait(3)\n",
    "                    batch = batch_table(returned_rows)\n",
    "                    browser.implicitly_wait(3)\n",
    "                    sleep(1)\n",
    "                    print('batch', batch.shape)\n",
    "                    sleep(1)\n",
    "                    month_table = pd.concat([month_table, batch], axis=0)\n",
    "                    sleep(1)\n",
    "                    browser.implicitly_wait(3)\n",
    "                    print('Month table rows:', month_table.shape[0])\n",
    "                    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selenium\n",
    "page_links = []\n",
    "browser = webdriver.Chrome('/Users/macbook/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://rodweb.bcgov.net/BrowserViewDMP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[2]/div/input'\n",
    "browser.find_element_by_xpath(path).send_keys('MARRIOTT OWNERSHIP RESORTS INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document type\n",
    "#path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[2]/div[2]/input'\n",
    "#browser.find_element_by_xpath(path).send_keys('RED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[2]/p/input'\n",
    "browser.find_element_by_xpath(path).send_keys('01/01/1982')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end date\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[3]/p/input'\n",
    "browser.find_element_by_xpath(path).send_keys('')\n",
    "# How to delete text in the form?\n",
    "# browser.find_element_by_xpath(path).clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click Search\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[3]/button[2]'\n",
    "browser.find_element_by_xpath(path).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    popup = browser.switch_to.alert\n",
    "    popup.text\n",
    "except:\n",
    "    print('Less than 1000 rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    records = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "    print(records)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    records_found = browser.find_element_by_xpath('//*[@id=\"results\"]/div[6]/div/div[2]').text\n",
    "    print(records_found)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.implicitly_wait(5)\n",
    "#browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[25]/div[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(browser)\n",
    "for _ in range(3):\n",
    "    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.DataFrame([])\n",
    "#table = pd.concat([table, get_table_batch(soup)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Test\n",
    "\n",
    "## Selenium\n",
    "page_links = []\n",
    "browser = webdriver.Chrome('/Users/macbook/Downloads/chromedriver')\n",
    "\n",
    "url = 'http://rodweb.bcgov.net/BrowserViewDMP/'\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[2]/div/input'\n",
    "browser.find_element_by_xpath(path).send_keys('MARRIOTT OWNERSHIP RESORTS INC')\n",
    "\n",
    "# document type\n",
    "#path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[2]/div[2]/input'\n",
    "#browser.find_element_by_xpath(path).send_keys('RED')\n",
    "\n",
    "# start date\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[2]/p/input'\n",
    "browser.find_element_by_xpath(path).send_keys('01/01/1982')\n",
    "\n",
    "# end date\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[3]/p/input'\n",
    "browser.find_element_by_xpath(path).send_keys('')\n",
    "# How to delete text in the form?\n",
    "# browser.find_element_by_xpath(path).clear()\n",
    "\n",
    "# click Search\n",
    "path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[3]/button[2]'\n",
    "browser.find_element_by_xpath(path).click()\n",
    "\n",
    "try:\n",
    "    popup = browser.switch_to.alert\n",
    "    popup.text\n",
    "except:\n",
    "    print('Less than 1000 rows')\n",
    "\n",
    "try:\n",
    "    records = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "    print(records)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    records_found = browser.find_element_by_xpath('//*[@id=\"results\"]/div[6]/div/div[2]').text\n",
    "    print(records_found)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#browser.implicitly_wait(5)\n",
    "#browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[25]/div[3]').click()\n",
    "\n",
    "actions = ActionChains(browser)\n",
    "for _ in range(3):\n",
    "    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "    sleep(1)\n",
    "\n",
    "#table = pd.DataFrame([])\n",
    "#table = pd.concat([table, get_table_batch(soup)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Scraping Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selenium\n",
    "browser = webdriver.Chrome('/Users/macbook/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://rodweb.bcgov.net/BrowserViewDMP/'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[2]/div/input'\n",
    "browser.find_element_by_xpath(owner_path).send_keys('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document type\n",
    "type_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[2]/div[2]/input'\n",
    "browser.find_element_by_xpath(type_path).send_keys('DEED,RED,REDC,REDH,REDM,TSD,TSDHH,TSDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date\n",
    "start_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[2]/p/input'\n",
    "browser.find_element_by_xpath(start_date_path).send_keys('02/01/2010')\n",
    "#browser.find_element_by_xpath(start_date_path).clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end date\n",
    "end_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[3]/p/input'\n",
    "browser.find_element_by_xpath(end_date_path).send_keys('02/30/2010')\n",
    "# How to delete text in the form?\n",
    "#browser.find_element_by_xpath(end_date_path).clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click Search\n",
    "search_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[3]/button[2]'\n",
    "browser.find_element_by_xpath(search_path).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view doc\n",
    "browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[4]/div[1]/button').click()\n",
    "#//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[26]/div[1]/button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_xpath('/html/body/div[1]/div[3]/ul/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to Search\n",
    "back_search_path = '/html/body/div[1]/div[3]/ul/li[1]/a'\n",
    "browser.find_element_by_xpath(back_search_path).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_table(total_rows):\n",
    "    table = pd.DataFrame([])\n",
    "    for i in range(0,5):\n",
    "        browser.implicitly_wait(1)\n",
    "        try:\n",
    "            if i == 0:\n",
    "                browser.implicitly_wait(3)\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                sleep(1)\n",
    "                try:\n",
    "                    #browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[10]/div[3]').click()\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[10]/div[3]'\n",
    "                    element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    print('except')\n",
    "                    browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[5]/div[3]').click()\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(3):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.2)\n",
    "            else:\n",
    "                browser.implicitly_wait(3)\n",
    "                sleep(0.5)\n",
    "                try:\n",
    "                    #browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[30]/div[3]').click()\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[30]/div[3]'\n",
    "                    element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[25]/div[3]').click()\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(2):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    browser.implicitly_wait(1)\n",
    "                    sleep(0.4)\n",
    "\n",
    "            if i%2==0:\n",
    "                sleep(1)\n",
    "                browser.implicitly_wait(4)\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                dupl = table[table.duplicated(subset=table.columns, keep='first')]\n",
    "\n",
    "            clean_table = table.drop_duplicates(subset=table.columns, keep='first').copy()\n",
    "            #if i%10==0:\n",
    "                #print('Parse try',i) # % of rows to finish\n",
    "            print(table.shape[0], dupl.shape[0], clean_table.shape[0])\n",
    "\n",
    "            if clean_table.shape[0] >= 0.995*total_rows:\n",
    "                #print('Batch table rows:', clean_table.shape[0])\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"row_xpath\")))\n",
    "\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[10]/div[3]'\n",
    "element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_table(422).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
