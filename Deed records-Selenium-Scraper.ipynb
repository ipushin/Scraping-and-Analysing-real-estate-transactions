{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle\n",
    "import requests\n",
    "import math\n",
    "from calendar import monthrange\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_batch(soup):\n",
    "    \n",
    "    party_code = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'party_code'})):\n",
    "        party_code.append(el.text)\n",
    "    \n",
    "    party_name = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'party_name'})):\n",
    "        if el.text != 'Name':\n",
    "            party_name.append(el.text)\n",
    "    \n",
    "    cross_party_name = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'cross_party_name'})):\n",
    "        if el.text != 'Cross Party':\n",
    "            cross_party_name.append(el.text)\n",
    "    \n",
    "    rec_date = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'rec_date'})):\n",
    "        if el.text != 'Date':\n",
    "            rec_date.append(el.text)\n",
    "    doc_type = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'doc_type'})):\n",
    "        if el.text != 'Type':\n",
    "            doc_type.append(el.text)\n",
    "    \n",
    "    book = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'book'})):\n",
    "        if el.text != 'Book':\n",
    "            book.append(el.text)\n",
    "    \n",
    "    page = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'page'})):\n",
    "        if el.text != 'Page':\n",
    "            page.append(el.text)\n",
    "    \n",
    "    legal_1 = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'legal_1'})):\n",
    "        if el.text != 'Legal':\n",
    "            legal_1.append(el.text)\n",
    "    \n",
    "    file_num = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'file_num'})):\n",
    "        if el.text != 'Instr#':\n",
    "            file_num.append(el.text)\n",
    "    \n",
    "    doc_status = []\n",
    "    for i, el in enumerate(soup.findAll('div', attrs={'colid':'doc_status'})):\n",
    "        if el.text != 'Status':\n",
    "            doc_status.append(el.text)\n",
    "    \n",
    "    batch = pd.DataFrame({'Party Code':party_code[1:],\n",
    "                          'Party Name':party_name,\n",
    "                          'Cross Party Name':cross_party_name,\n",
    "                          'Date':rec_date,\n",
    "                          'Doc Type':doc_type,\n",
    "                          'Book':book,\n",
    "                          'Page':page,\n",
    "                          'Legal':legal_1,\n",
    "                          'Instr#':file_num,\n",
    "                          'Doc Status':doc_status})\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_and_scrape(returned_rows):\n",
    "    table = pd.DataFrame([])\n",
    "    for i in range(0,50):\n",
    "        try:\n",
    "            browser.implicitly_wait(1)\n",
    "            if i == 0:\n",
    "                browser.implicitly_wait(3)\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                browser.implicitly_wait(1)\n",
    "                try:\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[10]/div[3]'\n",
    "                    element = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    print('except 10th element')\n",
    "                    browser.implicitly_wait(1)\n",
    "                    row = randint(3,10)\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[{}]/div[3]'.format(row)\n",
    "                    element = WebDriverWait(browser, 6).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(3):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.2)\n",
    "            else:\n",
    "                browser.implicitly_wait(0.5)\n",
    "                try:\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[30]/div[3]'\n",
    "                    element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click()\n",
    "                except:\n",
    "                    browser.implicitly_wait(1)\n",
    "                    row = randint(10,20)\n",
    "                    row_xpath = '//*[@id=\"center\"]/div/div[4]/div[2]/div/div/div[{}]/div[3]'.format(row)\n",
    "                    element = WebDriverWait(browser, 5).until(EC.element_to_be_clickable((By.XPATH, row_xpath)))\n",
    "                    element.click().click()\n",
    "                actions = ActionChains(browser)\n",
    "                for _ in range(2):\n",
    "                    actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "                    sleep(0.2)\n",
    "\n",
    "            if i%2==0:\n",
    "                browser.implicitly_wait(1)\n",
    "                sleep(0.1) \n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                table = pd.concat([table, get_table_batch(soup)], axis=0)\n",
    "                dupl = table[table.duplicated(subset=table.columns, keep='first')]\n",
    "\n",
    "            clean_table = table.drop_duplicates(subset=table.columns, keep='first').copy()\n",
    "            if clean_table.shape[0] >= 0.99*returned_rows:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[2]/p/input'\n",
    "end_date_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[4]/div[3]/p/input'\n",
    "search_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[3]/button[2]'\n",
    "back_search_path = '/html/body/div[1]/div[3]/ul/li[1]/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selenium\n",
    "browser = webdriver.Chrome('/Users/macbook/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://rodweb.bcgov.net/BrowserViewDMP/'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[1]/div[2]/div/input'\n",
    "browser.find_element_by_xpath(owner_path).send_keys('MARRIOTT OWNERSHIP RESORTS INC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document type\n",
    "type_path = '/html/body/div[1]/div[3]/div/div[1]/div/div/div/div[1]/form/div[2]/div[2]/input'\n",
    "browser.find_element_by_xpath(type_path).send_keys('DEED,RED,REDC,REDH,REDM,TSD,TSDHH,TSDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marriott_table=pd.read_csv('Marriott.csv', index_col=[0])\n",
    "#marriott_table.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marriott_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for year in range(2009,2021):\n",
    "    year = str(year)\n",
    "    for month_num in range(1,13):\n",
    "        month_table = pd.DataFrame([])\n",
    "        date_start = '01'\n",
    "        end_of_month = str(monthrange(int(year), month_num)[1])\n",
    "        comul_rows = 0\n",
    "        for i in range(30): \n",
    "            #print('\\n')\n",
    "            print('Batch #'+str(i))\n",
    "           \n",
    "            if i == 0:\n",
    "                date_end = str(monthrange(int(year), month_num)[1])\n",
    "            \n",
    "            if len(str(month_num)) < 2:\n",
    "                month = '0' + str(month_num)\n",
    "            else:\n",
    "                month = str(month_num)\n",
    "            returned_rows=1001\n",
    "            \n",
    "            # update end and start date       \n",
    "            browser.find_element_by_xpath(start_date_path).send_keys('{}/{}/{}'.format(month, date_start, year)) \n",
    "            browser.find_element_by_xpath(end_date_path).send_keys('{}/{}/{}'.format(month, date_end, year))\n",
    "\n",
    "            # click search\n",
    "            sleep(0.3)\n",
    "            browser.find_element_by_xpath(search_path).click()\n",
    "\n",
    "            try:\n",
    "                sleep(0.5)\n",
    "                ret_rows_path = '//*[@id=\"results\"]/div[6]/div/div[2]'\n",
    "                element = WebDriverWait(browser, randint(1,4)).until(EC.element_to_be_clickable((By.XPATH, ret_rows_path)))\n",
    "                returned_rows = element.text\n",
    "                returned_rows = int(re.findall(r'(\\d+(?= total))', returned_rows)[0])\n",
    "                comul_rows += returned_rows\n",
    "                #print('Comul Rows:', comul_rows)\n",
    "                print('Month', month, 'Date Start:', date_start, 'Date End:', date_end, 'Returned Rows:', returned_rows)\n",
    "\n",
    "                if date_start == '01' and date_end == end_of_month:\n",
    "                    rows_month_total = returned_rows\n",
    "                \n",
    "            except:\n",
    "                try:\n",
    "                    sleep(randint(2,3))\n",
    "                    #browser.implicitly_wait(3)\n",
    "                    popup = browser.switch_to.alert\n",
    "                    returned_rows = int(re.findall(r'(\\d+(?= results))', popup.text)[0])\n",
    "                    print('Month', month, 'Date Start:', date_start, 'Date End:', date_end, 'Returned Rows:', returned_rows)\n",
    "                    if date_start == '01' and date_end == end_of_month: \n",
    "                        rows_month_total = returned_rows\n",
    "                    \n",
    "                except:\n",
    "                    not_found = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "\n",
    "                    if not_found:\n",
    "                        print('No records')\n",
    "                        # back to search\n",
    "                        sleep(0.3)\n",
    "                        browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                        # clear end and start date\n",
    "                        browser.implicitly_wait(0.3)\n",
    "                        browser.find_element_by_xpath(end_date_path).clear()\n",
    "                        browser.find_element_by_xpath(start_date_path).clear()\n",
    "                        break\n",
    "\n",
    "            while returned_rows > 1000:\n",
    "                try:\n",
    "                    try:\n",
    "                        browser.implicitly_wait(3)\n",
    "                        alert = browser.switch_to_alert()\n",
    "                        alert.accept()\n",
    "                    except:\n",
    "                        continue\n",
    "                    try:\n",
    "                        # back to search\n",
    "                        element = WebDriverWait(browser, 3).until(EC.element_to_be_clickable((By.XPATH, back_search_path)))\n",
    "                        element.click()\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    # clear end date\n",
    "                    browser.implicitly_wait(1)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "\n",
    "                    # end date chuncking, update end date\n",
    "                    sleep(1)\n",
    "                    if len(date_start)>1 and date_start[0]==0:\n",
    "                        date_start_num = int(date_start[1])\n",
    "                    else:\n",
    "                        date_start_num = int((date_start))\n",
    "\n",
    "                    if len(date_end)>1 and date_end[0]==0:\n",
    "                        date_end_num = int(date_end[1])\n",
    "                    else:\n",
    "                        date_end_num = int((date_end))\n",
    "\n",
    "                    date_end = math.trunc(date_start_num + (date_end_num-date_start_num)/(returned_rows/1000))\n",
    "                    date_end = str(date_end)\n",
    "\n",
    "                    \n",
    "                    if len(date_end) < 2:\n",
    "                        date_end = '0' + date_end\n",
    "\n",
    "                    browser.find_element_by_xpath(end_date_path).send_keys('{}/{}/{}'.format(month,date_end,year))\n",
    "\n",
    "                    # click search\n",
    "                    browser.find_element_by_xpath(search_path).click()\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # check updated results\n",
    "                try:\n",
    "                    sleep(randint(2,3))\n",
    "                    popup = browser.switch_to.alert\n",
    "                    returned_rows = int(re.findall(r'(\\d+(?= results))', popup.text)[0])\n",
    "                    print('Date Start:', date_start, ' Updated Date End:', date_end, 'Returned rows:', returned_rows)\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        returned_rows = browser.find_element_by_xpath('//*[@id=\"results\"]/div[6]/div/div[2]').text\n",
    "                        returned_rows = int(re.findall(r'(\\d+(?= total))', returned_rows)[0])\n",
    "                        comul_rows += returned_rows\n",
    "                        print('Comul Rows:', comul_rows)\n",
    "                        print('Date Start:', date_start, ' Updated Date End:', date_end, 'Returned rows:', returned_rows)\n",
    "                        \n",
    "                    except:\n",
    "                        returned_rows = 999\n",
    "                        not_found = browser.find_element_by_xpath('//*[@id=\"notFound\"]/div/div/p').text\n",
    "                        if not_found:\n",
    "                            returned_rows = 999\n",
    "                            pass\n",
    "\n",
    "            # if <1000 on the first step\n",
    "            else:\n",
    "                if returned_rows < 60:\n",
    "                    sleep(0.5)\n",
    "                    html = browser.page_source\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    batch = get_table_batch(soup)\n",
    "                    month_table = pd.concat([month_table, batch], axis=0)\n",
    "\n",
    "                    # back to search\n",
    "                    browser.implicitly_wait(1.5)\n",
    "                    browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                    # clear end and start date\n",
    "                    browser.implicitly_wait(0.3)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "                    browser.find_element_by_xpath(start_date_path).clear()\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "        \n",
    "                    batch = scroll_and_scrape(returned_rows)\n",
    "                    print('Batch Rows:', batch.shape[0], 'Percent of records: {}%'.format(round(batch.shape[0]/returned_rows*100, 1)))\n",
    "                    sleep(0.5) \n",
    "                    month_table = pd.concat([month_table, batch], axis=0)\n",
    "                    month_table['Start Date'] = date_start\n",
    "                    month_table['End Date'] = date_end\n",
    "                    month_table['Percentage of data'] = round(batch.shape[0]/returned_rows*100, 1)\n",
    "\n",
    "                    date_start = str(int(date_end)+1)\n",
    "\n",
    "                    #EDIT\n",
    "                    if date_end==end_of_month: \n",
    "                    #print('Final Step', 'Rows Month Total:', rows_month_total)\n",
    "                        print('Month table rows:', month_table.shape[0], 'Percent of total: {}%'.format(round(month_table.shape[0]/rows_month_total*100, 1))) \n",
    "                        # back to search\n",
    "                        sleep(0.3)\n",
    "                        browser.implicitly_wait(1)\n",
    "                        browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                        # clear end and start date\n",
    "                        browser.implicitly_wait(0.3)\n",
    "                        browser.find_element_by_xpath(end_date_path).clear()\n",
    "                        browser.find_element_by_xpath(start_date_path).clear()\n",
    "\n",
    "                        break\n",
    "\n",
    "                    date_end = math.trunc(int(date_start) + (int(end_of_month)-int(date_start))/((rows_month_total-comul_rows*0.99)/1000))\n",
    "                    if date_end > int(end_of_month):\n",
    "                        date_end = end_of_month\n",
    "                    date_end = str(date_end)\n",
    "                    if len(date_end) < 2:\n",
    "                            date_end = '0' + date_end\n",
    "\n",
    "                    if len(date_start) < 2:\n",
    "                        date_start = '0' + date_start\n",
    "\n",
    "\n",
    "                    if len(date_start) < 2:\n",
    "                        date_start = '0' + date_start\n",
    "\n",
    "                    # back to search\n",
    "                    sleep(0.3)\n",
    "                    browser.implicitly_wait(1)\n",
    "                    browser.find_element_by_xpath(back_search_path).click()\n",
    "\n",
    "                    # clear end and start date\n",
    "                    browser.implicitly_wait(0.3)\n",
    "                    browser.find_element_by_xpath(end_date_path).clear()\n",
    "                    browser.find_element_by_xpath(start_date_path).clear()\n",
    "\n",
    "        \n",
    "        #marriott_table = pd.concat([marriott_table, month_table], axis=0)\n",
    "        #marriott_table.to_csv('----.csv')\n",
    "        print('Marriott Table Rows:', marriott_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_table_final.to_csv('timeshares_{}'.format('2012'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_table.drop_duplicates(subset=year_table.columns[:8], keep='first').shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
